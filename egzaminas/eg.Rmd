---
title: "Egzaminas"
author: "Simas"
date: "May 29, 2016"
output: html_document
---

```{r,message=FALSE}
library(car)
library(fpp)
library(dynlm)
library(knitr)
```
1. Uzduotis
-

2. Uzduotis 
1) dalis
a)

```{r}
data<-read.csv("data1.csv", header=T)
## duomenis teko pertvarkyti, istryniau "missing" juos uzvadinau data1.csv
head(data)
## is markes nepadarysiu dummy variable todel ju nenaudosiu modelyje
```

b)

```{r}
## iškokime išskirčių 
##Sukurkime modeli i kuri ieina visi kintamieji
model1 <- lm(data$kaina~data$rida+data$amzius+data$galia, data = data)
## ieskome isskirciu
outlierTest(model1)
## 19 stebejimas identifikuojamas kaip iskirtis, iesmetame ji
data<-data[-19,]
## ir ismetu paskutini stulpeli nes nemoku su juo elgtis (reiktu daryti zymini kintamaji)
data<-data[,-5]
```

c)

```{r}
plot(data) ## nepanasu, kad kazkas butu koreliuota
summary(data) ## paziuriu i vidurkius, medianas
```

d)

```{r}
## http://stackoverflow.com/questions/17200114/how-to-split-data-into-training-testing-sets-using-s## ample-function-in-r-program is cia paemiau duomenu padalinima
library(dplyr)
trainSet<-sample_frac(data, 0.8)
a<-as.numeric(rownames(trainSet)) # because rownames() returns character
testSet<-data[-a,]
## padalinau duomenis
```

2)dalis
a)

```{r}
model2 <- lm(data$kaina~data$rida+data$amzius+data$galia, data = data)
```

b)

```{r}
summary(model2)
## kazkokia nesamone gavosi, bet galia ir rida yra reiksmingi
```

c)

```{r}
vif(model2)
## visi vif<10, multikolinearumo problemos nera
hist(model2$res)
## nepanasu akd paklaidos normalios
shapiro.test(model2$res)
## p-value>0.05, paklaidos nera normalios
library(lmtest)
bptest(model2)
# p-value > 0.05, vadinasi duomenys yra hetero. Sia problema pavyks apeiti su coeftest

## Heteroskedastiskumo problema reiskia, kad OLS metudo gauti ivertiniai nera BLUE ( Best Linear 
## Unbiased Estimators) ir ju sklaida nera maziausia is visu galimu nepaslinktu iverciu. Taip pat
## del heteroskedastiskumo negalime pasikliauti iverciu standard errors, kuriu paslinktumas gali
## suklaidinti ir mes padarysime 2 rusies klaida priimdami H0.
## Heteroskedastiskumo problema galima isspresti logaritmuojant duomenis, 
## naudoti weighted least squares metoda

## Jei paklaidos nera normaliosios, tai galim gauti bloga F statistika. Taip pat mes nebegalime    ## teigti, kad koficientai turi t- pasiskirstyma. 

## Multikolinearumo problema padidina koficientu standard errors, kas padidina antros rusies 
## klaidos tikimybe. Taip apt multikolinearumo problema lemia tai, kad smulkus pakeitimai 
## duomenyse gali privesti prie dideliu pokyciu modelyje (netgi pakeisti ivercio zenkla).
## Heteroskedastiskumo problema galima isspresti ismetant du stipriai koreliuotus kintamuosius 
## (turincius dideli vif), taip pat galime naudoti principal components arba  Partial Least Squares ## Regression (PLS), dar galime naudoti kintamuju skirtumus su funkcija d().

## taip apt sias problemas gali padeti isspresti coeftest uris duoda ta pati ka ir summary, tik kad
## yra istaisytas heteroskedastiskusmas
```

3. Uzduotis
1) dalis
a)

```{r}
duom<-M1Germany
modelis1 <- dynlm(duom$logm1~L(duom$logprice, 1)) ## sudarome prasoma modeli
```

b)

```{r}
serOrg<-modelis1$res
serOrg<-as.ts(serOrg)
```

c)

```{r}
## Pirmas budas
plot(serOrg)
acf(serOrg) ## duomenys sezoniniai
stl_serOrg<-stl(serOrg, s.window="periodic")
stl_seasonal<-stl_serOrg$time.series[,"seasonal"] ## isisaugome seasonal stulpeli
pirmas_budas<-serOrg-stl_seasonal

## antras budas

modelis2<-lm(serOrg~stl_seasonal) ## sudarome prasoma regresija
antras_budas<-as.ts(modelis2$res)

## palyginsime

acf(pirmas_budas)
acf(antras_budas)
## grafikai identiški, nesimato sezoniškumo, tad tiesiog rinksiuosi pirmąjį
ser<-pirmas_budas
```

d)

```{r}
plot(ser) 
##  sezoniškumo nėra trendo irgi, bet ar duomenys pakankamai horizontalus ir ar ju variacija 
## pastovi sunku pasakyti pabandykime naudoti ndiffs funkcija, ka jinai sakys
ns1<-ndiffs(ser) ## surandame diferencijavimo eile
ns1
## matome kad diferencijuoti nebereikia, bent jau pagal ndiffs funkcij1 (tikriausiai duomenys 
## stacionarus)
kpss.test(ser) ## patkrinkim su testu
## p-value>0.05 H0 priimame, duomenys stacionaruss ir nesezoniniai.
## Darau isvada, kad laiko eilute ser stacionari
```

e) 

```{r}
plot(ser) 
## svyravimai skirtingais laiko momentasi yra skirtingi, manau box.cox būtų naudinga.
lambda1<-BoxCox.lambda(ser) ## randame lambda
ser1<-BoxCox(ser,lambda1) ## atliekame transformacija
plot(ser1, main="transformuoti duomenys")
## akivaizdu, kad transformacija nieko reiksmingo neatliko, klydau, transformacijos nereikia
```


2) dalis
a)

```{r}
mod1<-ets(ser)
mod1[13]
## (A,N,N) A- addictive errors, N- no trend, N- no season

```

b)

```{r}

```

c)

```{r}
mod3<-auto.arima(ser)
mod3
## (p,d,q)(P,D,Q)
## Mazosios raides- nesezonine modelio dalis
## p - autoregresine modelio dalis
## d - diferencijavimo eile
## q - moving average modelio dalis
## Didziosios raides raides tas pats kas ir mazosios tiesiog jos yra skirtos sezoniniai modelio 
## daliai aprasyti. Indeksas salia antruju skliaustu reiskia periodu skaiciu per sezona.
## Taip integravimo eiles sutampa.
```

d)

```{r}
acf(ser)
pacf(ser)
## bandysiu tokius modelius
band1=arima(ser, order = c(2,0,0),seasonal = list(order=c(2,0,0),period=4))
band2=arima(ser, order = c(0,0,1),seasonal = list(order=c(0,0,1),period=4))
accuracy(mod1)
accuracy(mod3)
accuracy(band1)
accuracy(band2)
## pagal rmse geriausiais band1
mod4<-band1
```

3) dalis
a)

```{r}
acf(mod1$res)
acf(mod3$res)
acf(band2$res)
acf(mod4$res)
## is acf tik band2 modelio liekanos nepanasios i baltaji triuksma
par(mfrow=c(2,2))
Box.test(mod1$res, type="Lj")
Box.test(mod3$res, type="Lj")
Box.test(band2$res, type="Lj")
Box.test(mod4$res, type="Lj")
## pagal testo p-value tik band2 modelio liekanos nera baltasis triuksmas
## darau isvada kad visu modeliu iskyrus band2 liekas yra baltasis triuksmas
```

b)

```{r}
trainSet<-window(ser, end=c(1985,4))
testSet<-window(ser, start=c(1986,1))
```

c)

```{r}
mod1_1<-ets(trainSet)
mod2_2<-auto.arima(trainSet)
mod3_3<-arima(trainSet, order = c(2,0,0),seasonal = list(order=c(2,0,0),period=4))
mod4_4<-arima(trainSet, order = c(0,0,1),seasonal = list(order=c(0,0,1),period=4))
```

d)

```{r}
library(ggplot2)
f_mod1_1<-forecast(mod1_1, h=50)
f_mod2_2<-forecast(mod2_2, h=50)
f_mod3_3<-forecast(mod3_3, h=50)
f_mod4_4<-forecast(mod4_4, h=50)
## Nemoku ant prognozes grafiko isbrezti tikruju reiksmiu (testSet), todel isbresiu atskirai 
## prognoze su paskliautinuoju intervalu ir tada ant vieno grafiko isbresiu kaip kiekviena prognoze ## prognozuoja lyginant su tikromis reiksmemis
autoplot(f_mod1_1)
autoplot(f_mod2_2)
autoplot(f_mod3_3) ## prognozes su pasikliautinaisiais intervalais
autoplot(f_mod4_4)

plot(ser, col="red")
lines(f_mod1_1$mean, col="green",lwd=2)
lines(f_mod2_2$mean, col="blue",lwd=2)
lines(f_mod3_3$mean, col="yellow",lwd=2)  ## grafikas su tikromis reiksmemis ir prognozemis
lines(f_mod4_4$mean, col="orange",lwd=2)
## matome kad visos prognozes is pradziu prognozuoja skirtingai bet paskui prognozes sueina i dvi ## skirtingas konstantas
```

e)

```{r}
tab1 = rbind(
  accuracy(f_mod1_1, ser)[,2],
  accuracy(f_mod2_2, ser)[,2],
  accuracy(f_mod3_3, ser)[,2],
  accuracy(f_mod4_4, ser)[,2]
)
rownames(tab1) <- c("f_mod1_1", "f_mod2_2", "f_mod3_3", "f_mod4_4")
kable(tab1, digits=3)
## training sete geriausiai pasirode mod3_3, test sete ji vos vos pralenke mod4_4 bet pastarasis 
## daugiau atsiliko training sete. Rinkciausi  mod3_3, nes jis buvo geriausias ir pagal accuracy
## ir jo paklaidos yra baltasis triuksmas
modMain<-mod3_3
```
